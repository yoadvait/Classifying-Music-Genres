# Music Genre Classification using Deep Learning

This project focuses on classifying music genres using a hybrid **CNN-LSTM** model. The classification is based on features extracted from audio signals, specifically **Mel-Frequency Cepstral Coefficients (MFCCs)**, leveraging deep learning architectures to differentiate between various music genres.

---

## Table of Contents
- [Introduction](#introduction)
- [Project Structure](#project-structure)
- [Data Preprocessing](#data-preprocessing)
- [Training](#training)
- [Usage](#usage)
- [Blog](#complete-blog)


---

## Introduction

Music genre classification is the task of categorizing music tracks into predefined genres based on their audio features. In this project, we utilize deep learning techniques to classify audio tracks into one of ten genres. We use `MFCCs` to extract relevant features from the raw audio, which are then fed into different models like a hybrid `CNN-LSTM` model. The convolutional layers help capture spatial patterns from the MFCCs, while the LSTM layers capture temporal dependencies.

---

## Project Structure

```bash
MusicGenreClassification/
│
├── Data/                          # Folder for dataset (MFCCs, labels, raw audio files)
│   ├── genres_original/            # Raw audio data (organized by genre folders)
│   ├── mfccs.npy                   # Preprocessed MFCCs (generated by the DataPreprocessor)
│   └── labels.npy                  # Labels corresponding to MFCCs
│
├── saved_models/                   # Directory for saving the trained models
│   └── hybrid_model/               # Trained hybrid CNN-LSTM model
│
├── src/                            # Source code folder
│   ├── components/
│   │   ├── data_preprocessing.py   # Script for data preprocessing and MFCC extraction
│   │   └── prediction.py           # Script for making predictions using the trained model
│   │
│   ├── models/
│   │   └── hybrid.py               # Script containing the CNN-LSTM model architecture
│   │
│   ├── logger.py                   # Logging configuration
│   └── main.py                     # Main script to run the training pipeline
│
└── README.md                       # Project documentation
```


## Data Preprocessing

The `DataPreprocessor` class extracts MFCC features and their associated labels from the audio dataset. The steps include:

    1. Reading the raw `.wav` files.
    2. Extracting MFCCs.
    3. Normalizing and saving the features into `.npy` files for fast access.

---

## Training

The model is trained using the `Adam` optimizer with a learning rate of 0.001 and the `categorical cross-entropy` loss function. Batch size and epochs can be tuned based on the dataset size and computational resources.

# Usage

## How to Run

Follow the steps below to clone the repository, install dependencies, prepare the dataset, preprocess it, and train the model.

### Steps to Run:

1. **Clone the repository**:
   ```bash
   git clone <repo_url>
   cd MusicGenreClassification
   ```

2. **Install the necessary dependencies**:
   ```bash
   pip install -r requirements.txt

   ```
3. **Prepare the dataset**: Place your dataset in the Data/genres_original/ folder and ensure it is structured as described in the Dataset section.
   ```bash
4. **Preprocess the dataset**: Run the script to preprocess the audio files and extract MFCC features:

   ```bash
   python app.py
   ```
   (The script will preprocess the dataset, train the model, and save the trained model to the `saved_models/` folder.)

5. **Make predictions** (if enabled in the script): You can make predictions on any new audio file using the GenrePredictor class.







Once the model is trained, you can use it to predict the genre of new audio files. Below is a step-by-step guide on how to utilize the `GenrePredictor` class for making predictions.

### *Making Predictions*


1. **Import the Required Class**: Start by importing the `GenrePredictor` class from the `prediction.py` module.

    2. **Specify the Model Path**: Define the path to the saved model you want to use for predictions. You can use either the `.keras` format or the `.h5` format.

    3. **Load the Predictor**: Create an instance of the `GenrePredictor` class, passing the model path.

    4. **Make Predictions**: Call the `make_prediction()` method, passing the path of the audio file you wish to classify.

## Example Code

Here’s an example of how to implement these steps in your code:

```python
from src.MusicGenreClassification.components.prediction import GenrePredictor
```
Specify the path to the saved model
```python
model_save_path = 'saved_models/hybrid_model.keras'  
```

 or 

```python
'saved_models/hybrid_model.h5'
```

#### Create an instance of GenrePredictor
```python
predictor = GenrePredictor(model_save_path)
```

#### Specify the path to the audio file you want to classify
```python
test_file_path = 'path/to/your/audio_file.wav'
```

#### Make the prediction
```python
predicted_genre = predictor.make_prediction(test_file_path)
```

#### Output the predicted genre
```python
print(f'Predicted Genre: {predicted_genre}')
```

## Complete Blog 
### @Hashnode

https://yoadvait.hashnode.dev/classifying-music-genres

